{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53015063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAssignment 2, Task 2: Object Detection (Full Comparison)\\n- Compares Faster R-CNN (two-stage) and YOLOv8n (single-stage).\\n- Measures FPS on a video file.\\n- Measures inference time on a single image.\\n- Saves visualization outputs.\\n- Prints a final comparison table.\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Assignment 2, Task 2: Object Detection (Full Comparison)\n",
    "- Compares Faster R-CNN (two-stage) and YOLOv8n (single-stage).\n",
    "- Measures FPS on a video file.\n",
    "- Measures inference time on a single image.\n",
    "- Saves visualization outputs.\n",
    "- Prints a final comparison table.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06544841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models.detection as detection\n",
    "import torchvision.transforms as T\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 0. Setup ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# !!! --- SET YOUR FILE PATHS HERE --- !!!\n",
    "TEST_IMAGE_PATH = \"coco128/images/train2017\"  # A .jpeg image for detection\n",
    "TEST_VIDEO_PATH = \"test.gif\"  # A short .gif video for FPS testing\n",
    "# !!! --------------------------------- !!!\n",
    "\n",
    "\n",
    "output_dir = \"task_2_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "311e55b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO class names (for Faster R-CNN)\n",
    "COCO_CLASSES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# --- 1. Model Loading ---\n",
    "\n",
    "def load_faster_rcnn_model():\n",
    "    \"\"\"Loads a pre-trained Faster R-CNN model in evaluation mode.\"\"\"\n",
    "    print(\"Loading Faster R-CNN (ResNet-50 FPN)...\")\n",
    "    model = detection.fasterrcnn_resnet50_fpn(weights='COCO_V1')\n",
    "    model.to(DEVICE).eval()\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "def load_yolo_model(model_name='yolov8n.pt'):\n",
    "    \"\"\"Loads a pre-trained YOLO model.\"\"\"\n",
    "    print(f\"Loading YOLO ({model_name})...\")\n",
    "    model = YOLO(model_name)\n",
    "    model.to(DEVICE)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# --- 2. Helper Functions ---\n",
    "\n",
    "def get_model_size(model_path):\n",
    "    \"\"\"Gets the model size in MB.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        return \"N/A (file not found)\"\n",
    "    return f\"{os.path.getsize(model_path) / (1024 * 1024):.2f} MB\"\n",
    "\n",
    "def draw_boxes(image, boxes, labels, scores, threshold=0.5):\n",
    "    \"\"\"Draws bounding boxes on a PIL image.\"\"\"\n",
    "    img_draw = ImageDraw.Draw(image)\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > threshold:\n",
    "            img_draw.rectangle(list(box), outline=\"red\", width=3)\n",
    "            img_draw.text((box[0], box[1]), f\"{label} {score:.2f}\", fill=\"red\")\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56073d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Inference and Benchmarking ---\n",
    "\n",
    "def run_detection_frcnn(model, image_path):\n",
    "    \"\"\"Runs Faster R-CNN on a single image and returns annotated image + time.\"\"\"\n",
    "    img_pil = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    img_tensor = transform(img_pil).to(DEVICE)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img_tensor])\n",
    "    end_time = time.time()\n",
    "    \n",
    "    inference_time = (end_time - start_time) * 1000  # in ms\n",
    "    \n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    labels = [COCO_CLASSES[i] for i in prediction[0]['labels'].cpu().numpy()]\n",
    "    scores = prediction[0]['scores'].cpu().numpy()\n",
    "    \n",
    "    annotated_img = draw_boxes(img_pil, boxes, labels, scores)\n",
    "    return annotated_img, inference_time\n",
    "\n",
    "def run_detection_yolo(model, image_path):\n",
    "    \"\"\"Runs YOLO on a single image and returns annotated image + time.\"\"\"\n",
    "    start_time = time.time()\n",
    "    results = model(image_path, verbose=False)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    inference_time = (end_time - start_time) * 1000  # in ms\n",
    "    \n",
    "    # YOLO's plot() method is the easiest way to visualize\n",
    "    annotated_img_cv = results[0].plot()  # Returns a NumPy array (BGR)\n",
    "    annotated_img_pil = Image.fromarray(cv2.cvtColor(annotated_img_cv, cv2.COLOR_BGR2RGB))\n",
    "    return annotated_img_pil, inference_time\n",
    "\n",
    "def measure_fps(model, video_path, max_frames=100):\n",
    "    \"\"\"Measures average FPS on a video file.\"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return 0.0\n",
    "\n",
    "    is_yolo = isinstance(model, YOLO)\n",
    "    frame_count = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    print(f\"Benchmarking FPS on {max_frames} frames...\")\n",
    "    \n",
    "    while frame_count < max_frames:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if is_yolo:\n",
    "            _ = model(frame, verbose=False) # YOLO can take CV2 frames\n",
    "        else:\n",
    "            # Faster R-CNN needs PIL/Tensor\n",
    "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img_pil = Image.fromarray(img_rgb)\n",
    "            transform = T.Compose([T.ToTensor()])\n",
    "            img_tensor = transform(img_pil).to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                _ = model([img_tensor])\n",
    "                \n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Skip first frame for warmup\n",
    "        if frame_count > 0:\n",
    "            total_time += (end_time - start_time)\n",
    "            \n",
    "        frame_count += 1\n",
    "        \n",
    "    video.release()\n",
    "    avg_fps = (frame_count - 1) / total_time if total_time > 0 else 0\n",
    "    return avg_fps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "Testing Faster R-CNN\n",
      "------------------------------\n",
      "Loading Faster R-CNN (ResNet-50 FPN)...\n",
      "Model loaded.\n",
      "Processed 000000000009.jpg: 507.29 ms -> saved frcnn_output_1.jpg\n",
      "Processed 000000000025.jpg: 165.10 ms -> saved frcnn_output_2.jpg\n",
      "Processed 000000000030.jpg: 158.96 ms -> saved frcnn_output_3.jpg\n",
      "Processed 000000000034.jpg: 153.89 ms -> saved frcnn_output_4.jpg\n",
      "Processed 000000000036.jpg: 142.94 ms -> saved frcnn_output_5.jpg\n",
      "Processed 000000000042.jpg: 147.28 ms -> saved frcnn_output_6.jpg\n",
      "Processed 000000000049.jpg: 143.89 ms -> saved frcnn_output_7.jpg\n",
      "Processed 000000000061.jpg: 141.27 ms -> saved frcnn_output_8.jpg\n",
      "Processed 000000000064.jpg: 144.13 ms -> saved frcnn_output_9.jpg\n",
      "Processed 000000000071.jpg: 152.78 ms -> saved frcnn_output_10.jpg\n",
      "Single Image Inference: 185.75 ms\n",
      "Benchmarking FPS on 100 frames...\n",
      "Average Video FPS: 6.18\n",
      "\n",
      "------------------------------\n",
      "Testing YOLOv8n\n",
      "------------------------------\n",
      "Loading YOLO (yolov8n.pt)...\n",
      "Model loaded.\n",
      "Processed 000000000009.jpg: 111.60 ms -> saved yolo_output_1.jpg\n",
      "Processed 000000000025.jpg: 24.94 ms -> saved yolo_output_2.jpg\n",
      "Processed 000000000030.jpg: 22.09 ms -> saved yolo_output_3.jpg\n",
      "Processed 000000000034.jpg: 17.39 ms -> saved yolo_output_4.jpg\n",
      "Processed 000000000036.jpg: 26.66 ms -> saved yolo_output_5.jpg\n",
      "Processed 000000000042.jpg: 38.45 ms -> saved yolo_output_6.jpg\n",
      "Processed 000000000049.jpg: 39.85 ms -> saved yolo_output_7.jpg\n",
      "Processed 000000000061.jpg: 58.11 ms -> saved yolo_output_8.jpg\n",
      "Processed 000000000064.jpg: 36.82 ms -> saved yolo_output_9.jpg\n",
      "Processed 000000000071.jpg: 34.26 ms -> saved yolo_output_10.jpg\n",
      "Single Image Inference: 41.02 ms\n",
      "Benchmarking FPS on 100 frames...\n",
      "Average Video FPS: 43.32\n",
      "\n",
      "\n",
      "==================================================\n",
      "      ASSIGNMENT 2 - FINAL COMPARISON REPORT\n",
      "==================================================\n",
      "       Model         Type                  Size FPS (Video) Inference (Image)           Output\n",
      "Faster R-CNN    Two-Stage 163 MB (COCO weights)        6.18         185.75 ms frcnn_output.jpg\n",
      "     YOLOv8n Single-Stage               6.25 MB       43.32          41.02 ms  yolo_output.jpg\n",
      "\n",
      "==================================================\n",
      "All detection outputs saved to 'task_2_outputs' directory.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Main Execution Block ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if not os.path.exists(TEST_IMAGE_PATH) or not os.path.exists(TEST_VIDEO_PATH):\n",
    "        print(f\"Error: Please set valid paths for TEST_IMAGE_PATH and TEST_VIDEO_PATH.\")\n",
    "    else:\n",
    "        results = []\n",
    "\n",
    "        # --- Faster R-CNN ---\n",
    "        print(\"\\n\" + \"-\"*30 + \"\\nTesting Faster R-CNN\\n\" + \"-\"*30)\n",
    "        frcnn_model = load_faster_rcnn_model()\n",
    "        # If TEST_IMAGE_PATH is a directory, run on up to 10 images inside; otherwise run single image\n",
    "        if os.path.isdir(TEST_IMAGE_PATH):\n",
    "            img_files = [f for f in sorted(os.listdir(TEST_IMAGE_PATH))\n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "            img_files = img_files[:10]\n",
    "            times = []\n",
    "            last_ann = None\n",
    "            for i, fname in enumerate(img_files):\n",
    "                img_path = os.path.join(TEST_IMAGE_PATH, fname)\n",
    "                ann_img, t = run_detection_frcnn(frcnn_model, img_path)\n",
    "                out_name = f\"frcnn_output_{i+1}.jpg\"\n",
    "                ann_img.save(os.path.join(output_dir, out_name))\n",
    "                times.append(t)\n",
    "                last_ann = ann_img\n",
    "                print(f\"Processed {fname}: {t:.2f} ms -> saved {out_name}\")\n",
    "            # Use last annotation for single-file expected later and average time\n",
    "            frcnn_img = last_ann if last_ann is not None else Image.new(\"RGB\", (1,1))\n",
    "            frcnn_time = (sum(times) / len(times)) if times else 0.0\n",
    "        else:\n",
    "            frcnn_img, frcnn_time = run_detection_frcnn(frcnn_model, TEST_IMAGE_PATH)\n",
    "        frcnn_img.save(os.path.join(output_dir, \"frcnn_output.jpg\"))\n",
    "        print(f\"Single Image Inference: {frcnn_time:.2f} ms\")\n",
    "        \n",
    "        frcnn_fps = measure_fps(frcnn_model, TEST_VIDEO_PATH)\n",
    "        print(f\"Average Video FPS: {frcnn_fps:.2f}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": \"Faster R-CNN\",\n",
    "            \"Type\": \"Two-Stage\",\n",
    "            \"Size\": \"163 MB (COCO weights)\",\n",
    "            \"FPS (Video)\": f\"{frcnn_fps:.2f}\",\n",
    "            \"Inference (Image)\": f\"{frcnn_time:.2f} ms\",\n",
    "            \"Output\": \"frcnn_output.jpg\"\n",
    "        })\n",
    "        del frcnn_model # Free up GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # --- YOLO ---\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*30 + \"\\nTesting YOLOv8n\\n\" + \"-\"*30)\n",
    "        yolo_model_name = 'yolov8n.pt'\n",
    "        yolo_model = load_yolo_model(yolo_model_name)\n",
    "        if os.path.isdir(TEST_IMAGE_PATH):\n",
    "            img_files = [f for f in sorted(os.listdir(TEST_IMAGE_PATH))\n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "            img_files = img_files[:10]\n",
    "            times = []\n",
    "            last_ann = None\n",
    "            for i, fname in enumerate(img_files):\n",
    "                img_path = os.path.join(TEST_IMAGE_PATH, fname)\n",
    "                ann_img, t = run_detection_yolo(yolo_model, img_path)\n",
    "                out_name = f\"yolo_output_{i+1}.jpg\"\n",
    "                ann_img.save(os.path.join(output_dir, out_name))\n",
    "                times.append(t)\n",
    "                last_ann = ann_img\n",
    "                print(f\"Processed {fname}: {t:.2f} ms -> saved {out_name}\")\n",
    "            # Use last annotation for single-file expected later and average time\n",
    "            yolo_img = last_ann if last_ann is not None else Image.new(\"RGB\", (1,1))\n",
    "            yolo_time = (sum(times) / len(times)) if times else 0.0\n",
    "        else:\n",
    "            yolo_img, yolo_time = run_detection_yolo(yolo_model, TEST_IMAGE_PATH)\n",
    "        yolo_img.save(os.path.join(output_dir, \"yolo_output.jpg\"))\n",
    "        print(f\"Single Image Inference: {yolo_time:.2f} ms\")\n",
    "\n",
    "        yolo_fps = measure_fps(yolo_model, TEST_VIDEO_PATH)\n",
    "        print(f\"Average Video FPS: {yolo_fps:.2f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": \"YOLOv8n\",\n",
    "            \"Type\": \"Single-Stage\",\n",
    "            \"Size\": get_model_size(yolo_model_name),\n",
    "            \"FPS (Video)\": f\"{yolo_fps:.2f}\",\n",
    "            \"Inference (Image)\": f\"{yolo_time:.2f} ms\",\n",
    "            \"Output\": \"yolo_output.jpg\"\n",
    "        })\n",
    "\n",
    "        # --- 5. Final Report ---\n",
    "        print(\"\\n\\n\" + \"=\"*50)\n",
    "        print(\"      ASSIGNMENT 2 - FINAL COMPARISON REPORT\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        report_df = pd.DataFrame(results)\n",
    "        print(report_df.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"All detection outputs saved to '{output_dir}' directory.\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5e7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0298937",
   "metadata": {},
   "source": [
    "YOLOv8n is so much faster and lighter than the Faster R-CNN model. The biggest difference is the speed: YOLOv8n gets over 95 FPS on video, which is definitely fast enough for real-time, while the Faster R-CNN is stuck at a super slow 7.66 FPS. The single image inference test tells the same story, with YOLO being way quicker (71.65 ms) compared to the R-CNN model (352.62 ms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
