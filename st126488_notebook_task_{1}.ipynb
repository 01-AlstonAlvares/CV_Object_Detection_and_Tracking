{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4faf0915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:32<00:00, 5.23MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Assignment 2, Task 1: Image Classification (Full Comparison)\n",
    "- Compares two models: SimpleCNN and ResNet-18\n",
    "- Compares two optimizers: SGD and Adam\n",
    "- Runs all 4 combinations and prints a final report.\n",
    "- Saves loss/accuracy plots for each run.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- 0. Setup ---\n",
    "NUM_EPOCHS = 10  # Keep this low for testing (e.g., 5-10)\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Create an output directory for plots\n",
    "output_dir = \"task_1_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- 1. Data Loading (CIFAR-10) ---\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224) if \"ResNet\" in \"ResNet18\" else (32, 32)), # ResNet needs 224x224\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Re-define transform for SimpleCNN\n",
    "transform_simple = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_dataset_simple = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_simple)\n",
    "test_dataset_simple = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_simple)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88f97d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\alsto/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 26.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training SimpleCNN with SGD ---\n",
      "Epoch 1/10 | Train Loss: 1.8338 | Train Acc: 31.94% | Val Loss: 1.5155 | Val Acc: 44.28%\n",
      "Epoch 2/10 | Train Loss: 1.4030 | Train Acc: 48.91% | Val Loss: 1.2845 | Val Acc: 53.88%\n",
      "Epoch 3/10 | Train Loss: 1.2357 | Train Acc: 55.88% | Val Loss: 1.1799 | Val Acc: 58.13%\n",
      "Epoch 4/10 | Train Loss: 1.1321 | Train Acc: 59.90% | Val Loss: 1.1669 | Val Acc: 58.48%\n",
      "Epoch 5/10 | Train Loss: 1.0590 | Train Acc: 62.46% | Val Loss: 1.1188 | Val Acc: 60.48%\n",
      "Epoch 6/10 | Train Loss: 1.0020 | Train Acc: 64.49% | Val Loss: 1.1616 | Val Acc: 60.21%\n",
      "Epoch 7/10 | Train Loss: 0.9473 | Train Acc: 66.16% | Val Loss: 1.1085 | Val Acc: 61.81%\n",
      "Epoch 8/10 | Train Loss: 0.9004 | Train Acc: 67.99% | Val Loss: 1.0659 | Val Acc: 63.53%\n",
      "Epoch 9/10 | Train Loss: 0.8673 | Train Acc: 69.17% | Val Loss: 1.0667 | Val Acc: 63.42%\n",
      "Epoch 10/10 | Train Loss: 0.8209 | Train Acc: 70.74% | Val Loss: 1.1136 | Val Acc: 62.42%\n",
      "Finished Training.\n",
      "Saved metrics plot to task_1_outputs\\SimpleCNN_SGD_metrics.png\n",
      "Saved confusion matrix to task_1_outputs\\SimpleCNN_SGD_confusion_matrix.png\n",
      "--- Training SimpleCNN with Adam ---\n",
      "Epoch 1/10 | Train Loss: 1.6551 | Train Acc: 39.27% | Val Loss: 1.4394 | Val Acc: 47.53%\n",
      "Epoch 2/10 | Train Loss: 1.3550 | Train Acc: 51.00% | Val Loss: 1.2939 | Val Acc: 52.98%\n",
      "Epoch 3/10 | Train Loss: 1.2170 | Train Acc: 56.32% | Val Loss: 1.1899 | Val Acc: 58.00%\n",
      "Epoch 4/10 | Train Loss: 1.1284 | Train Acc: 59.94% | Val Loss: 1.1519 | Val Acc: 59.00%\n",
      "Epoch 5/10 | Train Loss: 1.0635 | Train Acc: 62.12% | Val Loss: 1.0998 | Val Acc: 61.65%\n",
      "Epoch 6/10 | Train Loss: 1.0158 | Train Acc: 64.00% | Val Loss: 1.0923 | Val Acc: 61.74%\n",
      "Epoch 7/10 | Train Loss: 0.9673 | Train Acc: 65.68% | Val Loss: 1.0675 | Val Acc: 62.40%\n",
      "Epoch 8/10 | Train Loss: 0.9292 | Train Acc: 67.21% | Val Loss: 1.0540 | Val Acc: 63.40%\n",
      "Epoch 9/10 | Train Loss: 0.8962 | Train Acc: 68.31% | Val Loss: 1.0432 | Val Acc: 63.70%\n",
      "Epoch 10/10 | Train Loss: 0.8646 | Train Acc: 69.34% | Val Loss: 1.0442 | Val Acc: 63.94%\n",
      "Finished Training.\n",
      "Saved metrics plot to task_1_outputs\\SimpleCNN_Adam_metrics.png\n",
      "Saved confusion matrix to task_1_outputs\\SimpleCNN_Adam_confusion_matrix.png\n",
      "--- Training ResNet18 with SGD ---\n",
      "Epoch 1/10 | Train Loss: 0.7376 | Train Acc: 74.72% | Val Loss: 0.7193 | Val Acc: 75.81%\n",
      "Epoch 2/10 | Train Loss: 0.6337 | Train Acc: 78.37% | Val Loss: 0.6079 | Val Acc: 79.62%\n",
      "Epoch 3/10 | Train Loss: 0.6245 | Train Acc: 78.82% | Val Loss: 0.6080 | Val Acc: 79.54%\n",
      "Epoch 4/10 | Train Loss: 0.6114 | Train Acc: 79.24% | Val Loss: 0.6391 | Val Acc: 78.78%\n",
      "Epoch 5/10 | Train Loss: 0.6064 | Train Acc: 79.26% | Val Loss: 0.6003 | Val Acc: 80.01%\n",
      "Epoch 6/10 | Train Loss: 0.6061 | Train Acc: 79.35% | Val Loss: 0.6040 | Val Acc: 79.63%\n",
      "Epoch 7/10 | Train Loss: 0.5929 | Train Acc: 79.90% | Val Loss: 0.5844 | Val Acc: 80.39%\n",
      "Epoch 8/10 | Train Loss: 0.5913 | Train Acc: 79.93% | Val Loss: 0.6490 | Val Acc: 78.65%\n",
      "Epoch 9/10 | Train Loss: 0.5981 | Train Acc: 79.54% | Val Loss: 0.6810 | Val Acc: 77.82%\n",
      "Epoch 10/10 | Train Loss: 0.6028 | Train Acc: 79.70% | Val Loss: 0.6730 | Val Acc: 77.81%\n",
      "Finished Training.\n",
      "Saved metrics plot to task_1_outputs\\ResNet18_SGD_metrics.png\n",
      "Saved confusion matrix to task_1_outputs\\ResNet18_SGD_confusion_matrix.png\n",
      "--- Training ResNet18 with Adam ---\n",
      "Epoch 1/10 | Train Loss: 0.8268 | Train Acc: 73.23% | Val Loss: 0.6298 | Val Acc: 79.10%\n",
      "Epoch 2/10 | Train Loss: 0.6195 | Train Acc: 78.70% | Val Loss: 0.6085 | Val Acc: 78.80%\n",
      "Epoch 3/10 | Train Loss: 0.5888 | Train Acc: 79.68% | Val Loss: 0.5957 | Val Acc: 79.45%\n",
      "Epoch 4/10 | Train Loss: 0.5736 | Train Acc: 80.07% | Val Loss: 0.5768 | Val Acc: 80.44%\n",
      "Epoch 5/10 | Train Loss: 0.5623 | Train Acc: 80.42% | Val Loss: 0.5890 | Val Acc: 79.96%\n",
      "Epoch 6/10 | Train Loss: 0.5602 | Train Acc: 80.65% | Val Loss: 0.5579 | Val Acc: 81.02%\n",
      "Epoch 7/10 | Train Loss: 0.5551 | Train Acc: 80.63% | Val Loss: 0.5641 | Val Acc: 80.49%\n",
      "Epoch 8/10 | Train Loss: 0.5514 | Train Acc: 80.82% | Val Loss: 0.5744 | Val Acc: 80.55%\n",
      "Epoch 9/10 | Train Loss: 0.5509 | Train Acc: 80.95% | Val Loss: 0.5727 | Val Acc: 80.43%\n",
      "Epoch 10/10 | Train Loss: 0.5440 | Train Acc: 81.06% | Val Loss: 0.5597 | Val Acc: 80.95%\n",
      "Finished Training.\n",
      "Saved metrics plot to task_1_outputs\\ResNet18_Adam_metrics.png\n",
      "Saved confusion matrix to task_1_outputs\\ResNet18_Adam_confusion_matrix.png\n",
      "\n",
      "\n",
      "==================================================\n",
      "      ASSIGNMENT 1 - FINAL COMPARISON REPORT\n",
      "==================================================\n",
      "    Model Optimizer Final Val Accuracy Training Time (s)\n",
      "SimpleCNN       SGD             62.42%            151.28\n",
      "SimpleCNN      Adam             63.94%            157.85\n",
      " ResNet18       SGD             77.81%           1166.83\n",
      " ResNet18      Adam             80.95%           1218.18\n",
      "\n",
      "==================================================\n",
      "All plots saved to 'task_1_outputs' directory.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Model Definitions ---\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"A simple baseline CNN for CIFAR-10 (32x32 images).\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_resnet_model(num_classes=10):\n",
    "    \"\"\"Loads a pre-trained ResNet-18 and adapts it for CIFAR-10.\"\"\"\n",
    "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n",
    "# --- 3. Training and Evaluation Loop ---\n",
    "\n",
    "def train_model(model, model_name, optimizer_name, optimizer, train_loader, test_loader, criterion, num_epochs=NUM_EPOCHS):\n",
    "    print(f\"--- Training {model_name} with {optimizer_name} ---\")\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader)\n",
    "        epoch_train_acc = 100 * correct / total\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_val_loss = val_loss / len(test_loader)\n",
    "        epoch_val_acc = 100 * correct / total\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.2f}%\")\n",
    "\n",
    "    print(\"Finished Training.\")\n",
    "    \n",
    "    # Save plots\n",
    "    plot_loss_accuracy(history, f\"{model_name}_{optimizer_name}\")\n",
    "    plot_confusion_matrix(all_labels, all_preds, class_names, f\"{model_name}_{optimizer_name}\")\n",
    "    \n",
    "    return epoch_val_acc, history\n",
    "\n",
    "# --- 4. Visualization Functions ---\n",
    "\n",
    "def plot_loss_accuracy(history, run_name):\n",
    "    \"\"\"Plots and saves training and validation loss/accuracy curves.\"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'bo-', label='Training loss')\n",
    "    plt.plot(epochs, history['val_loss'], 'ro-', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'bo-', label='Training acc')\n",
    "    plt.plot(epochs, history['val_acc'], 'ro-', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    save_path = os.path.join(output_dir, f\"{run_name}_metrics.png\")\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Saved metrics plot to {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_preds, class_names, run_name):\n",
    "    \"\"\"Plots and saves a confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix - {run_name}')\n",
    "    \n",
    "    save_path = os.path.join(output_dir, f\"{run_name}_confusion_matrix.png\")\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Saved confusion matrix to {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# --- 5. Main Execution Block ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Define all comparison configurations\n",
    "    models_to_run = {\n",
    "        \"SimpleCNN\": (SimpleCNN(num_classes=10), train_dataset_simple, test_dataset_simple),\n",
    "        \"ResNet18\": (get_resnet_model(num_classes=10), train_dataset, test_dataset)\n",
    "    }\n",
    "    \n",
    "    optimizers_to_run = {\n",
    "        \"SGD\": (optim.SGD, {\"lr\": 0.01, \"momentum\": 0.9}),\n",
    "        \"Adam\": (optim.Adam, {\"lr\": 0.001})\n",
    "    }\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    results = []\n",
    "\n",
    "    for model_name, (model_instance, train_data, test_data) in models_to_run.items():\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        for opt_name, (opt_class, opt_params) in optimizers_to_run.items():\n",
    "            \n",
    "            # Re-initialize model and optimizer for a fresh run\n",
    "            if model_name == \"SimpleCNN\":\n",
    "                model = SimpleCNN(num_classes=10).to(DEVICE)\n",
    "            else:\n",
    "                model = get_resnet_model(num_classes=10).to(DEVICE)\n",
    "                \n",
    "            optimizer = opt_class(model.parameters(), **opt_params)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            final_acc, _ = train_model(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                optimizer_name=opt_name,\n",
    "                optimizer=optimizer,\n",
    "                train_loader=train_loader,\n",
    "                test_loader=test_loader,\n",
    "                criterion=criterion\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            \n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Optimizer\": opt_name,\n",
    "                \"Final Val Accuracy\": f\"{final_acc:.2f}%\",\n",
    "                \"Training Time (s)\": f\"{end_time - start_time:.2f}\"\n",
    "            })\n",
    "\n",
    "    # --- 6. Final Report ---\n",
    "    print(\"\\n\\n\" + \"=\"*50)\n",
    "    print(\"      ASSIGNMENT 1 - FINAL COMPARISON REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    report_df = pd.DataFrame(results)\n",
    "    print(report_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"All plots saved to '{output_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dcc41d",
   "metadata": {},
   "source": [
    "Based on these results, it looks like the ResNet18 model is way better at this task than the SimpleCNN, getting a much higher validation accuracy around 78-81% compared to only 62-64%. But the trade-off is that the ResNet18 model took a lot longer to train, like over 1100 seconds, while the SimpleCNN was super fast at around 150 seconds. It also seems like for both models, the Adam optimizer worked a little better than SGD, giving us the best overall accuracy of 80.95% when used with ResNet18, though it did take slightly more time to train than SGD in both cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
